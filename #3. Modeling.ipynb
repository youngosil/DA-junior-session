{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPR/abcLUqtCNpmeF1omviv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4wmUoE3fzOXY","executionInfo":{"status":"ok","timestamp":1680520282113,"user_tz":-540,"elapsed":25862,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"b9d5b983-d7af-40e1-ebd0-edbe16aab8c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","import lightgbm as lgb\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"hirb-Thyz4-z","executionInfo":{"status":"ok","timestamp":1680523015615,"user_tz":-540,"elapsed":410,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/creditcard.csv')"],"metadata":{"id":"AI_l_X0u0Jnx","executionInfo":{"status":"ok","timestamp":1680520358541,"user_tz":-540,"elapsed":5570,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESzu_AzY0ZH6","executionInfo":{"status":"ok","timestamp":1680520396528,"user_tz":-540,"elapsed":14,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"25ea25b7-3fa0-4058-e032-cd539bcff023"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 284807 entries, 0 to 284806\n","Data columns (total 31 columns):\n"," #   Column  Non-Null Count   Dtype  \n","---  ------  --------------   -----  \n"," 0   Time    284807 non-null  float64\n"," 1   V1      284807 non-null  float64\n"," 2   V2      284807 non-null  float64\n"," 3   V3      284807 non-null  float64\n"," 4   V4      284807 non-null  float64\n"," 5   V5      284807 non-null  float64\n"," 6   V6      284807 non-null  float64\n"," 7   V7      284807 non-null  float64\n"," 8   V8      284807 non-null  float64\n"," 9   V9      284807 non-null  float64\n"," 10  V10     284807 non-null  float64\n"," 11  V11     284807 non-null  float64\n"," 12  V12     284807 non-null  float64\n"," 13  V13     284807 non-null  float64\n"," 14  V14     284807 non-null  float64\n"," 15  V15     284807 non-null  float64\n"," 16  V16     284807 non-null  float64\n"," 17  V17     284807 non-null  float64\n"," 18  V18     284807 non-null  float64\n"," 19  V19     284807 non-null  float64\n"," 20  V20     284807 non-null  float64\n"," 21  V21     284807 non-null  float64\n"," 22  V22     284807 non-null  float64\n"," 23  V23     284807 non-null  float64\n"," 24  V24     284807 non-null  float64\n"," 25  V25     284807 non-null  float64\n"," 26  V26     284807 non-null  float64\n"," 27  V27     284807 non-null  float64\n"," 28  V28     284807 non-null  float64\n"," 29  Amount  284807 non-null  float64\n"," 30  Class   284807 non-null  int64  \n","dtypes: float64(30), int64(1)\n","memory usage: 67.4 MB\n"]}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"JakeAFVX0cKM","executionInfo":{"status":"ok","timestamp":1680520528718,"user_tz":-540,"elapsed":18,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"eac55838-8d71-4e11-c3ca-111cad6f71ea"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Time         V1         V2        V3        V4        V5  \\\n","0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n","1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n","2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n","3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n","4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n","...          ...        ...        ...       ...       ...       ...   \n","284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n","284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n","284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n","284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n","284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n","\n","              V6        V7        V8        V9  ...       V21       V22  \\\n","0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n","1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n","2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n","3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n","4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n","...          ...       ...       ...       ...  ...       ...       ...   \n","284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n","284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n","284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n","284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n","284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n","\n","             V23       V24       V25       V26       V27       V28  Amount  \\\n","0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n","1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n","2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n","3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n","4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n","...          ...       ...       ...       ...       ...       ...     ...   \n","284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n","284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n","284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n","284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n","284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n","\n","        Class  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  \n","...       ...  \n","284802      0  \n","284803      0  \n","284804      0  \n","284805      0  \n","284806      0  \n","\n","[284807 rows x 31 columns]"],"text/html":["\n","  <div id=\"df-cbc6e24d-ee46-4043-bd48-dcecf63e16b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>...</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>...</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>284802</th>\n","      <td>172786.0</td>\n","      <td>-11.881118</td>\n","      <td>10.071785</td>\n","      <td>-9.834783</td>\n","      <td>-2.066656</td>\n","      <td>-5.364473</td>\n","      <td>-2.606837</td>\n","      <td>-4.918215</td>\n","      <td>7.305334</td>\n","      <td>1.914428</td>\n","      <td>...</td>\n","      <td>0.213454</td>\n","      <td>0.111864</td>\n","      <td>1.014480</td>\n","      <td>-0.509348</td>\n","      <td>1.436807</td>\n","      <td>0.250034</td>\n","      <td>0.943651</td>\n","      <td>0.823731</td>\n","      <td>0.77</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284803</th>\n","      <td>172787.0</td>\n","      <td>-0.732789</td>\n","      <td>-0.055080</td>\n","      <td>2.035030</td>\n","      <td>-0.738589</td>\n","      <td>0.868229</td>\n","      <td>1.058415</td>\n","      <td>0.024330</td>\n","      <td>0.294869</td>\n","      <td>0.584800</td>\n","      <td>...</td>\n","      <td>0.214205</td>\n","      <td>0.924384</td>\n","      <td>0.012463</td>\n","      <td>-1.016226</td>\n","      <td>-0.606624</td>\n","      <td>-0.395255</td>\n","      <td>0.068472</td>\n","      <td>-0.053527</td>\n","      <td>24.79</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284804</th>\n","      <td>172788.0</td>\n","      <td>1.919565</td>\n","      <td>-0.301254</td>\n","      <td>-3.249640</td>\n","      <td>-0.557828</td>\n","      <td>2.630515</td>\n","      <td>3.031260</td>\n","      <td>-0.296827</td>\n","      <td>0.708417</td>\n","      <td>0.432454</td>\n","      <td>...</td>\n","      <td>0.232045</td>\n","      <td>0.578229</td>\n","      <td>-0.037501</td>\n","      <td>0.640134</td>\n","      <td>0.265745</td>\n","      <td>-0.087371</td>\n","      <td>0.004455</td>\n","      <td>-0.026561</td>\n","      <td>67.88</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284805</th>\n","      <td>172788.0</td>\n","      <td>-0.240440</td>\n","      <td>0.530483</td>\n","      <td>0.702510</td>\n","      <td>0.689799</td>\n","      <td>-0.377961</td>\n","      <td>0.623708</td>\n","      <td>-0.686180</td>\n","      <td>0.679145</td>\n","      <td>0.392087</td>\n","      <td>...</td>\n","      <td>0.265245</td>\n","      <td>0.800049</td>\n","      <td>-0.163298</td>\n","      <td>0.123205</td>\n","      <td>-0.569159</td>\n","      <td>0.546668</td>\n","      <td>0.108821</td>\n","      <td>0.104533</td>\n","      <td>10.00</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>284806</th>\n","      <td>172792.0</td>\n","      <td>-0.533413</td>\n","      <td>-0.189733</td>\n","      <td>0.703337</td>\n","      <td>-0.506271</td>\n","      <td>-0.012546</td>\n","      <td>-0.649617</td>\n","      <td>1.577006</td>\n","      <td>-0.414650</td>\n","      <td>0.486180</td>\n","      <td>...</td>\n","      <td>0.261057</td>\n","      <td>0.643078</td>\n","      <td>0.376777</td>\n","      <td>0.008797</td>\n","      <td>-0.473649</td>\n","      <td>-0.818267</td>\n","      <td>-0.002415</td>\n","      <td>0.013649</td>\n","      <td>217.00</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>284807 rows × 31 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbc6e24d-ee46-4043-bd48-dcecf63e16b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cbc6e24d-ee46-4043-bd48-dcecf63e16b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cbc6e24d-ee46-4043-bd48-dcecf63e16b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# xgboost"],"metadata":{"id":"j_M4d26J437G"}},{"cell_type":"markdown","source":["hyper parameter\n","---------\n","|하이퍼 파라미터|설명|\n","|----|--|\n","|eta(default=0.3)|학습률, weak learner의 반영 수준을 나타냄, 범위는 0-1로 클수록 모형 업데이트 속도 faster, overfitting 이슈 발생 가능성 high|\n","|num_boost_around(default=10)|학습에 활용될 weak learners의 반복수|\n","|min_child_weight(default=1)|leaf node에 포함되는 최소 관측치의 수, 작은 값을 가질수록 overfitting 가능성 높음, 범위 : 0~|\n","|gamma(default=0)|leaf node의 추가 분할을 결정할 최소손실 감소값, 해당값보다 손실이 크게 감소할 때 분리, 값이 클수록 과적합 감소 효과, 범위 : 0~|\n","|5. max_depth(default=6)|트리의 최대 깊이 설정, 0으로 지정하면 깊이의 제한 x, overfitting에 가장 민감하게 작용하는 파라미터 중 하나, 범위 : 0~|\n","|6. sub_sample(default=1)|학습 시 데이터 샘플링 비율을 지정, 일반적으로 0.5~1 사이의 값을 사용, 범위 : 0~1|\n","|7. colsample_bytree(default=1)|트리 생성에 필요한 feature의 샘플링에 사용, feature가 많을 때 과적합 조절에 사용, 범위 : 0~1|\n","|8. lambda(default=1)|L2 Regularization 적용값, feature 개수가 많을 때 적용 검토, 클수록 과적합 감소 효과|\n","|9. alpha(default=0)|L1 Regularization 적용값, feature 개수가 많을 때 적용 검토, 클수록 과적합 감소 효과|\n","|10. scale_pos_weight(default=1)|불균형 데이터셋의 균형을 유지|"],"metadata":{"id":"UpiWQtvv2380"}},{"cell_type":"code","source":["# 데이터 전처리\n","# 불필요한 열 제거\n","data.drop(['Time'], axis=1, inplace=True)\n","# 타겟 변수와 특징 변수 나누기\n","target = 'Class'\n","features = [col for col in data.columns if col != target]\n","\n","# 훈련 데이터와 검증 데이터 나누기\n","train_data, val_data, train_target, val_target = train_test_split(\n","    data[features], data[target], test_size=0.2, random_state=42)"],"metadata":{"id":"DCnOBQa88WR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# XGBoost 모델 학습시키기\n","params = {\n","    'objective': 'binary:logistic',\n","    'eval_metric': 'auc',\n","    'eta': 0.1,\n","    'max_depth': 6,\n","    'min_child_weight': 1,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'seed': 42\n","}\n","dtrain = xgb.DMatrix(train_data, train_target)\n","dval = xgb.DMatrix(val_data, val_target)\n","model = xgb.train(params, dtrain, num_boost_round=1000, evals=[(dval, 'val')],\n","                  early_stopping_rounds=10, verbose_eval=10)\n","\n","# 검증 데이터에서 예측하기\n","val_pred = model.predict(dval)\n","\n","# 검증 데이터에서 AUC 평가하기\n","val_auc = roc_auc_score(val_target, val_pred)\n","print(f'검증 데이터에서 AUC: {val_auc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_LLv2Lr91vxm","executionInfo":{"status":"ok","timestamp":1680520949480,"user_tz":-540,"elapsed":15461,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"a762a548-6ffb-4836-8880-32f65e84cfce"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\tval-auc:0.92327\n","[10]\tval-auc:0.92320\n","[12]\tval-auc:0.92320\n","검증 데이터에서 AUC: 0.9232\n"]}]},{"cell_type":"markdown","source":["# LGBM"],"metadata":{"id":"seKXV1zi5CU3"}},{"cell_type":"markdown","source":["hyper paramater\n","---\n","|하이퍼파라미터|설명|\n","|--------------|----|\n","|objective\t|목적 함수. 이진 분류를 수행하므로 'binary'로 설정|\n","|metric|\t모델 성능 평가 지표. AUC 사용|\n","|learning_rate|\t학습률. 너무 높으면 수렴하지 못하고, 너무 낮으면 수렴 속도가 느리므로 적절한 값을 설정|\n","|num_leaves|\t결정 트리의 최대 잎 노드 개수. 과적합 방지를 위해 적절한 값을 설정|\n","|max_depth|\t결정 트리의 최대 깊이. None으로 설정하면 깊이에 제한이 없어 과적합 가능성이 높아짐|\n","|min_child_samples|\t잎 노드에 최소한으로 필요한 데이터 수. 적은 값은 깊은 트리를 만들어 과적합 가능성이 있음|\n","|subsample\t|각 트리 학습에 사용할 데이터 샘플링 비율|\n","|colsample_bytree\t|각 트리 학습에 사용할 특성 샘플링 비율|\n","|reg_alpha\t|L1 정규화 파라미터|\n","|reg_lambda\t|L2 정규화 파라미터|\n","|n_jobs\t|학습에 사용할 CPU 코어 수. -1로 설정하면 모든 코어 사용|\n","|random_state\t|랜덤 시드 값|"],"metadata":{"id":"iEuSkivW5p4G"}},{"cell_type":"code","source":["# LightGBM 모델 학습시키기\n","params = {\n","    'objective': 'binary',\n","    'metric': 'auc',\n","    'learning_rate': 0.05,\n","    'num_leaves': 31,\n","    'max_depth': -1,\n","    'min_child_samples': 20,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'reg_alpha': 0.1,\n","    'reg_lambda': 0.1,\n","    'n_jobs': -1,\n","    'random_state': 42\n","}\n","dtrain = lgb.Dataset(train_data, train_target)\n","dval = lgb.Dataset(val_data, val_target)\n","model = lgb.train(params, dtrain, num_boost_round=1000, valid_sets=[dtrain, dval],\n","                  early_stopping_rounds=10, verbose_eval=10)\n","\n","# 검증 데이터에서 예측하기\n","val_pred = model.predict(val_data)\n","\n","# 검증 데이터에서 AUC 평가하기\n","val_auc = roc_auc_score(val_target, val_pred)\n","print(f'검증 데이터에서 AUC: {val_auc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcEDw5AG5EdI","executionInfo":{"status":"ok","timestamp":1680522070730,"user_tz":-540,"elapsed":5609,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"9c3e8ca7-16df-4cfb-cbfe-717a57eb5c60"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 394, number of negative: 227451\n","[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117018 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 7395\n","[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001729 -> initscore=-6.358339\n","[LightGBM] [Info] Start training from score -6.358339\n","Training until validation scores don't improve for 10 rounds\n","[10]\ttraining's auc: 0.988588\tvalid_1's auc: 0.96869\n","Early stopping, best iteration is:\n","[7]\ttraining's auc: 0.987413\tvalid_1's auc: 0.970097\n","검증 데이터에서 AUC: 0.9701\n"]}]},{"cell_type":"code","source":["# LightGBM 모델 학습시키기\n","params = {\n","    'objective': 'binary',\n","    'metric': 'auc',\n","    'learning_rate': 0.05,\n","    'num_leaves': 31,\n","    'max_depth': -1,\n","    'min_child_samples': 20,\n","    'subsample': 0.8,\n","    'colsample_bytree': 0.8,\n","    'reg_alpha': 0.1,\n","    'reg_lambda': 0.1,\n","    'n_jobs': -1,\n","    'random_state': 42\n","}\n","dtrain = lgb.Dataset(train_data, train_target)\n","dval = lgb.Dataset(val_data, val_target)\n","model = lgb.train(params, dtrain, num_boost_round=1000, valid_sets=[dtrain, dval],\n","                  early_stopping_rounds=10, verbose_eval=10)\n","\n","# 검증 데이터에서 예측하기\n","val_pred = model.predict(val_data)\n","\n","# 검증 데이터에서 AUC 평가하기\n","val_auc = roc_auc_score(val_target, val_pred)\n","print(f'검증 데이터에서 AUC: {val_auc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1J0G1r8E5gOy","executionInfo":{"status":"ok","timestamp":1680521784046,"user_tz":-540,"elapsed":3691,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"f3733ea2-e350-4af0-9c44-165d203fa836"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 394, number of negative: 227451\n","[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053167 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 7395\n","[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001729 -> initscore=-6.358339\n","[LightGBM] [Info] Start training from score -6.358339\n","Training until validation scores don't improve for 10 rounds\n","[10]\ttraining's auc: 0.988588\tvalid_1's auc: 0.96869\n","Early stopping, best iteration is:\n","[7]\ttraining's auc: 0.987413\tvalid_1's auc: 0.970097\n","검증 데이터에서 AUC: 0.9701\n"]}]},{"cell_type":"markdown","source":["#RF"],"metadata":{"id":"WfQp_hXZ6kH7"}},{"cell_type":"markdown","source":["hyper parameter\n","---\n","|하이퍼파라미터|설명|\n","|--------------|----|\n","|n_estimators|생성할 결정 트리 개수|\n","|max_depth|\t결정 트리의 최대 깊이|\n","|random_state|\t랜덤 시드 값|\n"],"metadata":{"id":"3wNdHV2u6l2m"}},{"cell_type":"code","source":["# 데이터 전처리\n","# 불필요한 열 제거\n","data.drop(['Time'], axis=1, inplace=True)\n","# 타겟 변수와 특징 변수 나누기\n","target = 'Class'\n","features = [col for col in data.columns if col != target]\n","\n","# 훈련 데이터와 검증 데이터 나누기\n","train_data, val_data, train_target, val_target = train_test_split(\n","    data[features], data[target], test_size=0.2, random_state=42)"],"metadata":{"id":"sWXQdLIo9FaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 랜덤 포레스트 모델 생성 및 학습\n","model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n","model.fit(train_data, train_target)\n","\n","# 예측 결과 출력\n","val_pred = model.predict(val_data)\n","print(classification_report(val_target, val_pred))\n","print(confusion_matrix(val_target, val_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2itP7ZA5-gN","executionInfo":{"status":"ok","timestamp":1680523241056,"user_tz":-540,"elapsed":219637,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"4fb2fa2e-9485-4b23-c3ce-d2405caf512a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     56864\n","           1       0.97      0.79      0.87        98\n","\n","    accuracy                           1.00     56962\n","   macro avg       0.99      0.89      0.93     56962\n","weighted avg       1.00      1.00      1.00     56962\n","\n","[[56862     2]\n"," [   21    77]]\n"]}]},{"cell_type":"code","source":["# 랜덤 포레스트 모델 생성 및 학습\n","model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n","model.fit(train_data, train_target)\n","\n","# 예측 결과 출력\n","val_pred = model.predict(val_data)\n","print(classification_report(val_target, val_pred))\n","print(confusion_matrix(val_target, val_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HCO2kzs87si","executionInfo":{"status":"ok","timestamp":1680523497616,"user_tz":-540,"elapsed":256571,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"f553603f-efb9-4e16-f645-64a677cc287a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     56864\n","           1       0.97      0.73      0.84        98\n","\n","    accuracy                           1.00     56962\n","   macro avg       0.99      0.87      0.92     56962\n","weighted avg       1.00      1.00      1.00     56962\n","\n","[[56862     2]\n"," [   26    72]]\n"]}]},{"cell_type":"code","source":["# 랜덤 포레스트 모델 생성 및 학습\n","model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=0)\n","model.fit(train_data, train_target)\n","\n","# 예측 결과 출력\n","val_pred = model.predict(val_data)\n","print(classification_report(val_target, val_pred))\n","print(confusion_matrix(val_target, val_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8pWKlvA9iVk","executionInfo":{"status":"ok","timestamp":1680523942447,"user_tz":-540,"elapsed":444862,"user":{"displayName":"SOHYEON EOM","userId":"17766137155305456507"}},"outputId":"f00316fa-6587-494e-ea2b-56e51d2ddb44"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     56864\n","           1       0.97      0.77      0.86        98\n","\n","    accuracy                           1.00     56962\n","   macro avg       0.99      0.88      0.93     56962\n","weighted avg       1.00      1.00      1.00     56962\n","\n","[[56862     2]\n"," [   23    75]]\n"]}]}]}